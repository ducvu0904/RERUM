{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def seed_everything(seed):\n",
    "    \"\"\"\n",
    "    Set random seed for reproducibility\n",
    "    \"\"\"\n",
    "    # 1. Python & Numpy\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # 2. PyTorch (CPU & GPU)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "    print(f\"ðŸ”’ Locked Random Seed: {seed}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def seed_everything_random():\n",
    "    \"\"\"\n",
    "    Táº¡o random seed, set seed Ä‘Ã³, vÃ  return seed Ä‘á»ƒ báº¡n biáº¿t\n",
    "    \"\"\"\n",
    "    # Táº¡o random seed\n",
    "    random_seed = random.randint(0, 999999)\n",
    "    \n",
    "    # Set seed\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    random.seed(random_seed)\n",
    "    \n",
    "    # Äá»ƒ reproducible\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "    return random_seed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "null count:\n",
      "recency            0\n",
      "history_segment    0\n",
      "history            0\n",
      "mens               0\n",
      "womens             0\n",
      "zip_code           0\n",
      "newbie             0\n",
      "channel            0\n",
      "visit              0\n",
      "conversion         0\n",
      "spend              0\n",
      "treatment          0\n",
      "dtype: int64\n",
      "---------------------------\n",
      "recency              int64\n",
      "history_segment      int64\n",
      "history            float64\n",
      "mens                 int64\n",
      "womens               int64\n",
      "zip_code            object\n",
      "newbie               int64\n",
      "channel             object\n",
      "visit                int64\n",
      "conversion           int64\n",
      "spend              float64\n",
      "treatment            int64\n",
      "dtype: object\n",
      "---------------------------\n",
      "labels:\n",
      "['recency', 'history_segment', 'history', 'mens', 'womens', 'zip_code', 'newbie', 'channel', 'visit', 'conversion', 'spend', 'treatment']\n",
      "---------------------------\n",
      "data shape:\n",
      "(42613, 12)\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "df_men =pd.read_csv(r\"C:\\Users\\Lenovo\\Documents\\Rankability uplift modeling\\Hillstrom-Men.csv\")\n",
    "df_men = df_men.drop(columns=\"Unnamed: 0\")\n",
    "print (\"---------------------------\")\n",
    "print (\"null count:\")\n",
    "print (df_men.isnull().sum())\n",
    "print (\"---------------------------\")\n",
    "print(df_men.dtypes)\n",
    "print (\"---------------------------\")\n",
    "print (\"labels:\")\n",
    "print(df_men.columns.tolist())\n",
    "print (\"---------------------------\")\n",
    "print(\"data shape:\")\n",
    "print(df_men.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Train/Val/Test split with stratification ONLY by treatment (NO DATA LEAKAGE)\n",
      "Train: (25567, 10), Val: (4262, 10), Test: (12784, 10)\n",
      "Treatment distribution - Train: 50.00%, Val: 50.00%, Test: 50.00%\n",
      "Spend mean - Train: 1.00, Val: 0.95, Test: 1.14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.36323828, -0.95770591, -0.65534372, ...,  1.22273126,\n",
       "        -0.87900784,  1.12185957],\n",
       "       [ 0.63260109, -0.30863193, -0.31367375, ...,  1.22273126,\n",
       "        -0.87900784,  1.12185957],\n",
       "       [ 0.34748118, -0.30863193, -0.4344948 , ...,  1.22273126,\n",
       "         1.13764628, -0.89137716],\n",
       "       ...,\n",
       "       [ 0.34748118,  0.34044206,  0.30319097, ..., -0.8178412 ,\n",
       "        -0.87900784,  1.12185957],\n",
       "       [-1.07811837,  0.34044206,  0.16319135, ..., -0.8178412 ,\n",
       "         1.13764628, -0.89137716],\n",
       "       [-0.79299846, -0.95770591, -0.61911315, ..., -0.8178412 ,\n",
       "        -0.87900784,  1.12185957]], shape=(25567, 10))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hillstrom-men\n",
    "#split num and cate\n",
    "cate_cols = ['zip_code', 'channel']\n",
    "num_cols = ['recency', 'history_segment', 'history']\n",
    "#split x y t\n",
    "y_men = df_men[\"spend\"]\n",
    "t_men = df_men[\"treatment\"]\n",
    "x_men = df_men.drop(columns=[\"spend\", \"treatment\", \"visit\", \"conversion\"])\n",
    "\n",
    "# x_men_encode = pd.get_dummies(x_men, columns=cate_cols, drop_first=True)\n",
    "# x_men_encode = x_men_encode.astype(float)\n",
    "\n",
    "#train test split - stratify CHá»ˆ báº±ng treatment\n",
    "x_men_train, x_men_test, t_men_train, t_men_test, y_men_train, y_men_test = train_test_split(\n",
    "    x_men, t_men.values, y_men.values,\n",
    "    test_size=0.3, random_state=42, stratify= t_men\n",
    ")\n",
    "\n",
    "# Táº¡o stratify cho val split - chá»‰ dÃ¹ng treatment\n",
    "stratify_var_train = pd.Series(t_men_train)\n",
    "\n",
    "x_men_train, x_men_val, t_men_train, t_men_val, y_men_train, y_men_val = train_test_split(\n",
    "    x_men_train, t_men_train, y_men_train,\n",
    "    test_size=(1/7), random_state=42, stratify= t_men_train\n",
    ")\n",
    "\n",
    "# Fit get_dummies trÃªn train, sau Ä‘Ã³ align vá»›i val/test\n",
    "x_men_train_encode = pd.get_dummies(x_men_train, columns=cate_cols, drop_first=True)\n",
    "x_men_val_encode = pd.get_dummies(x_men_val, columns=cate_cols, drop_first=True)\n",
    "x_men_test_encode = pd.get_dummies(x_men_test, columns=cate_cols, drop_first=True)\n",
    "\n",
    "# Align columns\n",
    "x_men_val_encode = x_men_val_encode.reindex(columns=x_men_train_encode.columns, fill_value=0)\n",
    "x_men_test_encode = x_men_test_encode.reindex(columns=x_men_train_encode.columns, fill_value=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_men_train= scaler.fit_transform(x_men_train_encode)\n",
    "x_men_val = scaler.transform(x_men_val_encode)\n",
    "x_men_test = scaler.transform(x_men_test_encode)\n",
    "\n",
    "print (\"âœ… Train/Val/Test split with stratification ONLY by treatment (NO DATA LEAKAGE)\")\n",
    "print (f\"Train: {x_men_train.shape}, Val: {x_men_val.shape}, Test: {x_men_test.shape}\")\n",
    "print (f\"Treatment distribution - Train: {np.mean(t_men_train):.2%}, Val: {np.mean(t_men_val):.2%}, Test: {np.mean(t_men_test):.2%}\")\n",
    "print (f\"Spend mean - Train: {np.mean(y_men_train):.2f}, Val: {np.mean(y_men_val):.2f}, Test: {np.mean(y_men_test):.2f}\")\n",
    "\n",
    "# x_men = pd.DataFrame(x_men_train)\n",
    "x_men_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------\n",
      "âœ…Completed tranform to tensorâœ…\n",
      "Shape of train: x=torch.Size([25567, 10]); y =torch.Size([25567, 1]); t=torch.Size([25567, 1])\n",
      "Shape of val: x=torch.Size([4262, 10]); y=torch.Size([4262, 1]); t=torch.Size([4262, 1])\n",
      "Shape of test: x=torch.Size([12784, 10]); y=torch.Size([12784, 1]); t=torch.Size([12784, 1])\n"
     ]
    }
   ],
   "source": [
    "#Transform to tensor\n",
    "def to_tensor(df):\n",
    "    return torch.tensor(df, dtype=torch.float32)\n",
    "\n",
    "x_men_train_t = to_tensor(x_men_train)\n",
    "x_men_val_t = to_tensor(x_men_val)\n",
    "x_men_test_t = to_tensor(x_men_test)\n",
    "\n",
    "y_men_train_t = to_tensor(y_men_train).unsqueeze(1)\n",
    "y_men_val_t = to_tensor(y_men_val).unsqueeze(1)\n",
    "y_men_test_t = to_tensor(y_men_test).unsqueeze(1)\n",
    "\n",
    "t_men_train_t = to_tensor(t_men_train.astype(float)).unsqueeze(1)\n",
    "t_men_val_t = to_tensor(t_men_val.astype(float)).unsqueeze(1)\n",
    "t_men_test_t = to_tensor(t_men_test.astype(float)).unsqueeze(1)\n",
    "\n",
    "# sampler = get_sampler(y_men_train_t, target_positive_ratio=0.2)\n",
    "\n",
    "#Data loader\n",
    "train_dataset = TensorDataset(x_men_train_t, t_men_train_t, y_men_train_t)\n",
    "val_dataset = TensorDataset(x_men_val_t, t_men_val_t, y_men_val_t)\n",
    "test_dataset = TensorDataset(x_men_test_t, t_men_test_t, y_men_test_t)\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "print (\"-------------------------------------------------------------\")\n",
    "print (\"âœ…Completed tranform to tensorâœ…\")\n",
    "print (f\"Shape of train: x={x_men_train_t.shape}; y ={y_men_train_t.shape}; t={t_men_train_t.shape}\")\n",
    "print (f\"Shape of val: x={x_men_val_t.shape}; y={y_men_val_t.shape}; t={t_men_val_t.shape}\")\n",
    "print (f\"Shape of test: x={x_men_test_t.shape}; y={y_men_test_t.shape}; t={t_men_test_t.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import auuc, auqc, lift, krcc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dragonnet import Dragonnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Data Distribution Check:\n",
      "Y train: mean=1.0015, std=14.5993\n",
      "Y train zeros: 25338 / 25567 (99.1%)\n",
      "\n",
      "Treatment balance:\n",
      "  Train: 12784 treated, 12783 control\n",
      "  Test:  6392 treated, 6392 control\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸ“Š Data Distribution Check:\")\n",
    "print(f\"Y train: mean={y_men_train.mean():.4f}, std={y_men_train.std():.4f}\")\n",
    "print(f\"Y train zeros: {(y_men_train == 0).sum()} / {len(y_men_train)} ({(y_men_train == 0).sum()/len(y_men_train)*100:.1f}%)\")\n",
    "print(f\"\\nTreatment balance:\")\n",
    "print(f\"  Train: {(t_men_train == 1).sum()} treated, {(t_men_train == 0).sum()} control\")\n",
    "print(f\"  Test:  {(t_men_test == 1).sum()} treated, {(t_men_test == 0).sum()} control\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epochs = 50\n",
      " alpha = 1\n",
      " beta = 1\n",
      " learning rate = 0.001\n",
      " weight decay = 0.0001\n",
      " early stop = qini\n",
      " use ema = True\n",
      " ema alpha = 0.15\n",
      " patience = 30\n",
      " share dropout = 0\n",
      " outcome dropout = 0\n",
      " shared hidden = 200\n",
      " outcome hidden = 100\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "alpha = 1\n",
    "beta = 1\n",
    "lr = 1e-3\n",
    "wd = 1e-4\n",
    "early_stop_metric = \"qini\"\n",
    "ema = True\n",
    "ema_alpha = 0.15\n",
    "patience = 30\n",
    "shared_dropout = 0\n",
    "outcome_droupout = 0 \n",
    "shared_hidden = 200\n",
    "outcome_hidden = 100\n",
    "\n",
    "print (f\" epochs = {epochs}\")\n",
    "print (f\" alpha = {alpha}\")\n",
    "print (f\" beta = {beta}\")\n",
    "print (f\" learning rate = {lr}\")\n",
    "print (f\" weight decay = {wd}\")\n",
    "print (f\" early stop = {early_stop_metric}\")\n",
    "print (f\" use ema = {ema}\")\n",
    "print (f\" ema alpha = {ema_alpha}\")\n",
    "print (f\" patience = {patience}\")\n",
    "print (f\" share dropout = {shared_dropout}\")\n",
    "print (f\" outcome dropout = {outcome_droupout}\")\n",
    "print (f\" shared hidden = {shared_hidden}\")\n",
    "print (f\" outcome hidden = {outcome_hidden}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”’ Locked Random Seed: 412312\n",
      "ðŸ”ƒðŸ”ƒðŸ”ƒBegin training DragonnetðŸ”ƒðŸ”ƒðŸ”ƒ\n",
      "ðŸ“Š Strategy: Two-Stage EMA Filter (alpha=0.15)\n",
      "   EMA filters noise spikes, Raw Qini determines peak height\n",
      "   Select checkpoint: raw_qini is highest AND raw_qini >= ema_qini\n",
      "Epoch 1/50 | Base Loss: 23452.7656 | Tarreg Loss: 23876.205078 | Total Loss: 23452.7656 | Val Loss: 12848.9748 | Raw Qini: -0.0957 | EMA Trend: -0.0957 | â­ NEW BEST (peak â‰¥ trend)\n",
      "Epoch 2/50 | Base Loss: 21.3994 | Tarreg Loss: 50.519516 | Total Loss: 21.3994 | Val Loss: 12847.1935 | Raw Qini: -1.3209 | EMA Trend: -0.2795 | (patience: 1/30)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m      2\u001b[39m seed_everything(seed)\n\u001b[32m      4\u001b[39m dragonnet = Dragonnet(input_dim=x_men_train_t.shape[\u001b[32m1\u001b[39m], epochs=epochs, \n\u001b[32m      5\u001b[39m                       alpha=alpha, \n\u001b[32m      6\u001b[39m                       beta= beta, \n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m                       shared_dropout=shared_dropout,\n\u001b[32m     16\u001b[39m                       early_stop_metric=early_stop_metric)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[43mdragonnet\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m (\u001b[33m\"\u001b[39m\u001b[33mComplete training\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     21\u001b[39m \u001b[38;5;28mprint\u001b[39m (\u001b[33m\"\u001b[39m\u001b[33mEvaluating baselineðŸ”ƒðŸ”ƒðŸ”ƒ\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\Documents\\Rankability uplift modeling\\Baseline\\dragonnet.py:89\u001b[39m, in \u001b[36mDragonnet.fit\u001b[39m\u001b[34m(self, train_loader, val_loader)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;66;03m# TÃ­nh Qini score trÃªn validation set sau má»—i epoch\u001b[39;00m\n\u001b[32m     88\u001b[39m val_qini = \u001b[38;5;28mself\u001b[39m.validate_qini(val_loader)\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m val_loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.use_ema:\n\u001b[32m     92\u001b[39m     \u001b[38;5;66;03m# Two-Stage Strategy: EMA as noise filter, raw Qini determines peak\u001b[39;00m\n\u001b[32m     93\u001b[39m     \n\u001b[32m     94\u001b[39m     \u001b[38;5;66;03m# Step 1: Update EMA trend (for filtering, not for selection)\u001b[39;00m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ema_qini \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\Documents\\Rankability uplift modeling\\Baseline\\dragonnet.py:175\u001b[39m, in \u001b[36mDragonnet.validate\u001b[39m\u001b[34m(self, val_loader)\u001b[39m\n\u001b[32m    173\u001b[39m val_loss=\u001b[32m0\u001b[39m\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_mask\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:732\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    729\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    730\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    731\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m732\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    734\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    735\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    736\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    738\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:1470\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1467\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1468\u001b[39m     \u001b[38;5;66;03m# no valid `self._rcvd_idx` is found (i.e., didn't break)\u001b[39;00m\n\u001b[32m   1469\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._persistent_workers:\n\u001b[32m-> \u001b[39m\u001b[32m1470\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_shutdown_workers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1471\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[32m   1473\u001b[39m \u001b[38;5;66;03m# Now `self._rcvd_idx` is the batch index we want to fetch\u001b[39;00m\n\u001b[32m   1474\u001b[39m \n\u001b[32m   1475\u001b[39m \u001b[38;5;66;03m# Check if the next sample has already been generated\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:1618\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._shutdown_workers\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1613\u001b[39m         \u001b[38;5;28mself\u001b[39m._mark_worker_as_unavailable(worker_id, shutdown=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   1614\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._workers:\n\u001b[32m   1615\u001b[39m     \u001b[38;5;66;03m# We should be able to join here, but in case anything went\u001b[39;00m\n\u001b[32m   1616\u001b[39m     \u001b[38;5;66;03m# wrong, we set a timeout and if the workers fail to join,\u001b[39;00m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;66;03m# they are killed in the `finally` block.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1618\u001b[39m     \u001b[43mw\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMP_STATUS_CHECK_INTERVAL\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1619\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._index_queues:\n\u001b[32m   1620\u001b[39m     q.cancel_join_thread()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Program Files\\Python311\\Lib\\multiprocessing\\process.py:149\u001b[39m, in \u001b[36mBaseProcess.join\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._parent_pid == os.getpid(), \u001b[33m'\u001b[39m\u001b[33mcan only join a child process\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._popen \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m'\u001b[39m\u001b[33mcan only join a started process\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m res = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_popen\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    151\u001b[39m     _children.discard(\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Program Files\\Python311\\Lib\\multiprocessing\\popen_spawn_win32.py:109\u001b[39m, in \u001b[36mPopen.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    107\u001b[39m     msecs = \u001b[38;5;28mmax\u001b[39m(\u001b[32m0\u001b[39m, \u001b[38;5;28mint\u001b[39m(timeout * \u001b[32m1000\u001b[39m + \u001b[32m0.5\u001b[39m))\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m res = _winapi.WaitForSingleObject(\u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m._handle), msecs)\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m res == _winapi.WAIT_OBJECT_0:\n\u001b[32m    111\u001b[39m     code = _winapi.GetExitCodeProcess(\u001b[38;5;28mself\u001b[39m._handle)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "seed = 412312\n",
    "seed_everything(seed)\n",
    "\n",
    "dragonnet = Dragonnet(input_dim=x_men_train_t.shape[1], epochs=epochs, \n",
    "                      alpha=alpha, \n",
    "                      beta= beta, \n",
    "                      learning_rate=lr, \n",
    "                      weight_decay=wd,\n",
    "                      use_ema=ema,\n",
    "                      ema_alpha=ema_alpha,\n",
    "                      patience=patience,\n",
    "                      shared_hidden=shared_hidden,\n",
    "                      outcome_hidden=outcome_hidden,\n",
    "                      outcome_droupout=outcome_droupout,\n",
    "                      shared_dropout=shared_dropout,\n",
    "                      early_stop_metric=early_stop_metric)\n",
    "dragonnet.fit(train_loader, val_loader)\n",
    "\n",
    "print (\"Complete training\")\n",
    "\n",
    "print (\"Evaluating baselineðŸ”ƒðŸ”ƒðŸ”ƒ\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "x_men_test_t_on_device = x_men_test_t.to(device)\n",
    "\n",
    "y0_pred, y1_pred, _,_ = dragonnet.predict(x_men_test_t_on_device)\n",
    "\n",
    "# Move predicted tensors back to CPU before converting to numpy arrays\n",
    "uplift_pred = (y1_pred - y0_pred).cpu().numpy().flatten()\n",
    "\n",
    "y_true = y_men_test_t.cpu().numpy().flatten() # Ensure true labels are also on CPU if they were ever moved\n",
    "t_true = t_men_test_t.cpu().numpy().flatten() # Ensure true treatments are also on CPU if they were ever moved\n",
    "\n",
    "auuc_score = auuc(y_true, t_true, uplift_pred, bins=100, plot=True)\n",
    "auqc_score = auqc(y_true, t_true, uplift_pred, bins=100, plot=True)\n",
    "lift_score = lift(y_true, t_true, uplift_pred, h=0.3)\n",
    "krcc_score = krcc(y_true, t_true, uplift_pred, bins= 100)\n",
    "\n",
    "print (\"-\"*40)\n",
    "print (f\"AUUC: {auuc_score:.3f}\")\n",
    "print (f\"AUQC: {auqc_score:.3f}\")\n",
    "print (f\"Lift: {lift_score:.3f}\")\n",
    "print (f\"KRCC: {krcc_score:.3f}\")\n",
    "print (f\"seed: {seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "seed_everything(seed)\n",
    "\n",
    "dragonnet = Dragonnet(input_dim=x_men_train_t.shape[1], epochs=epochs, \n",
    "                      alpha=alpha, \n",
    "                      beta= beta, \n",
    "                      learning_rate=lr, \n",
    "                      weight_decay=wd,\n",
    "                      use_ema=ema,\n",
    "                      ema_alpha=ema_alpha,\n",
    "                      patience=patience,\n",
    "                      shared_hidden=shared_hidden,\n",
    "                      outcome_hidden=outcome_hidden,\n",
    "                      outcome_droupout=outcome_droupout,\n",
    "                      shared_dropout=shared_dropout,\n",
    "                      early_stop_metric=early_stop_metric)\n",
    "dragonnet.fit(train_loader, val_loader)\n",
    "\n",
    "print (\"Complete training\")\n",
    "\n",
    "print (\"Evaluating baselineðŸ”ƒðŸ”ƒðŸ”ƒ\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "x_men_test_t_on_device = x_men_test_t.to(device)\n",
    "\n",
    "y0_pred, y1_pred, _,_ = dragonnet.predict(x_men_test_t_on_device)\n",
    "\n",
    "# Move predicted tensors back to CPU before converting to numpy arrays\n",
    "uplift_pred = (y1_pred - y0_pred).cpu().numpy().flatten()\n",
    "\n",
    "y_true = y_men_test_t.cpu().numpy().flatten() # Ensure true labels are also on CPU if they were ever moved\n",
    "t_true = t_men_test_t.cpu().numpy().flatten() # Ensure true treatments are also on CPU if they were ever moved\n",
    "\n",
    "auuc_score = auuc(y_true, t_true, uplift_pred, bins=100, plot=True)\n",
    "auqc_score = auqc(y_true, t_true, uplift_pred, bins=100, plot=True)\n",
    "lift_score = lift(y_true, t_true, uplift_pred, h=0.3)\n",
    "krcc_score = krcc(y_true, t_true, uplift_pred, bins= 100)\n",
    "\n",
    "print (\"-\"*40)\n",
    "print (f\"AUUC: {auuc_score:.3f}\")\n",
    "print (f\"AUQC: {auqc_score:.3f}\")\n",
    "print (f\"Lift: {lift_score:.3f}\")\n",
    "print (f\"KRCC: {krcc_score:.3f}\")\n",
    "print (f\"seed: {seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1874\n",
    "seed_everything(seed)\n",
    "\n",
    "dragonnet = Dragonnet(input_dim=x_men_train_t.shape[1], epochs=epochs, \n",
    "                      alpha=alpha, \n",
    "                      beta= beta, \n",
    "                      learning_rate=lr, \n",
    "                      weight_decay=wd,\n",
    "                      use_ema=ema,\n",
    "                      ema_alpha=ema_alpha,\n",
    "                      patience=patience,\n",
    "                      shared_hidden=shared_hidden,\n",
    "                      outcome_hidden=outcome_hidden,\n",
    "                      outcome_droupout=outcome_droupout,\n",
    "                      shared_dropout=shared_dropout,\n",
    "                      early_stop_metric=early_stop_metric)\n",
    "dragonnet.fit(train_loader, val_loader)\n",
    "\n",
    "print (\"Complete training\")\n",
    "\n",
    "print (\"Evaluating baselineðŸ”ƒðŸ”ƒðŸ”ƒ\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "x_men_test_t_on_device = x_men_test_t.to(device)\n",
    "\n",
    "y0_pred, y1_pred, _,_ = dragonnet.predict(x_men_test_t_on_device)\n",
    "\n",
    "# Move predicted tensors back to CPU before converting to numpy arrays\n",
    "uplift_pred = (y1_pred - y0_pred).cpu().numpy().flatten()\n",
    "\n",
    "y_true = y_men_test_t.cpu().numpy().flatten() # Ensure true labels are also on CPU if they were ever moved\n",
    "t_true = t_men_test_t.cpu().numpy().flatten() # Ensure true treatments are also on CPU if they were ever moved\n",
    "\n",
    "auuc_score = auuc(y_true, t_true, uplift_pred, bins=100, plot=True)\n",
    "auqc_score = auqc(y_true, t_true, uplift_pred, bins=100, plot=True)\n",
    "lift_score = lift(y_true, t_true, uplift_pred, h=0.3)\n",
    "krcc_score = krcc(y_true, t_true, uplift_pred, bins= 100)\n",
    "\n",
    "print (\"-\"*40)\n",
    "print (f\"AUUC: {auuc_score:.3f}\")\n",
    "print (f\"AUQC: {auqc_score:.3f}\")\n",
    "print (f\"Lift: {lift_score:.3f}\")\n",
    "print (f\"KRCC: {krcc_score:.3f}\")\n",
    "print (f\"seed: {seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 902745\n",
    "seed_everything(seed)\n",
    "\n",
    "dragonnet = Dragonnet(input_dim=x_men_train_t.shape[1], epochs=epochs, \n",
    "                      alpha=alpha, \n",
    "                      beta= beta, \n",
    "                      learning_rate=lr, \n",
    "                      weight_decay=wd,\n",
    "                      use_ema=ema,\n",
    "                      ema_alpha=ema_alpha,\n",
    "                      patience=patience,\n",
    "                      shared_hidden=shared_hidden,\n",
    "                      outcome_hidden=outcome_hidden,\n",
    "                      outcome_droupout=outcome_droupout,\n",
    "                      shared_dropout=shared_dropout,\n",
    "                      early_stop_metric=early_stop_metric)\n",
    "dragonnet.fit(train_loader, val_loader)\n",
    "\n",
    "print (\"Complete training\")\n",
    "\n",
    "print (\"Evaluating baselineðŸ”ƒðŸ”ƒðŸ”ƒ\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "x_men_test_t_on_device = x_men_test_t.to(device)\n",
    "\n",
    "y0_pred, y1_pred, _,_ = dragonnet.predict(x_men_test_t_on_device)\n",
    "\n",
    "# Move predicted tensors back to CPU before converting to numpy arrays\n",
    "uplift_pred = (y1_pred - y0_pred).cpu().numpy().flatten()\n",
    "\n",
    "y_true = y_men_test_t.cpu().numpy().flatten() # Ensure true labels are also on CPU if they were ever moved\n",
    "t_true = t_men_test_t.cpu().numpy().flatten() # Ensure true treatments are also on CPU if they were ever moved\n",
    "\n",
    "auuc_score = auuc(y_true, t_true, uplift_pred, bins=100, plot=True)\n",
    "auqc_score = auqc(y_true, t_true, uplift_pred, bins=100, plot=True)\n",
    "lift_score = lift(y_true, t_true, uplift_pred, h=0.3)\n",
    "krcc_score = krcc(y_true, t_true, uplift_pred, bins= 100)\n",
    "\n",
    "print (\"-\"*40)\n",
    "print (f\"AUUC: {auuc_score:.3f}\")\n",
    "print (f\"AUQC: {auqc_score:.3f}\")\n",
    "print (f\"Lift: {lift_score:.3f}\")\n",
    "print (f\"KRCC: {krcc_score:.3f}\")\n",
    "print (f\"seed: {seed}\")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "seed_everything(seed)\n",
    "\n",
    "dragonnet = Dragonnet(input_dim=x_men_train_t.shape[1], epochs=epochs, \n",
    "                      alpha=alpha, \n",
    "                      beta= beta, \n",
    "                      learning_rate=lr, \n",
    "                      weight_decay=wd,\n",
    "                      use_ema=ema,\n",
    "                      ema_alpha=ema_alpha,\n",
    "                      patience=patience,\n",
    "                      shared_hidden=shared_hidden,\n",
    "                      outcome_hidden=outcome_hidden,\n",
    "                      outcome_droupout=outcome_droupout,\n",
    "                      shared_dropout=shared_dropout,\n",
    "                      early_stop_metric=early_stop_metric)\n",
    "dragonnet.fit(train_loader, val_loader)\n",
    "\n",
    "print (\"Complete training\")\n",
    "\n",
    "print (\"Evaluating baselineðŸ”ƒðŸ”ƒðŸ”ƒ\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "x_men_test_t_on_device = x_men_test_t.to(device)\n",
    "\n",
    "y0_pred, y1_pred, _,_ = dragonnet.predict(x_men_test_t_on_device)\n",
    "\n",
    "# Move predicted tensors back to CPU before converting to numpy arrays\n",
    "uplift_pred = (y1_pred - y0_pred).cpu().numpy().flatten()\n",
    "\n",
    "y_true = y_men_test_t.cpu().numpy().flatten() # Ensure true labels are also on CPU if they were ever moved\n",
    "t_true = t_men_test_t.cpu().numpy().flatten() # Ensure true treatments are also on CPU if they were ever moved\n",
    "\n",
    "auuc_score = auuc(y_true, t_true, uplift_pred, bins=100, plot=True)\n",
    "auqc_score = auqc(y_true, t_true, uplift_pred, bins=100, plot=True)\n",
    "lift_score = lift(y_true, t_true, uplift_pred, h=0.3)\n",
    "krcc_score = krcc(y_true, t_true, uplift_pred, bins= 100)\n",
    "\n",
    "print (\"-\"*40)\n",
    "print (f\"AUUC: {auuc_score:.3f}\")\n",
    "print (f\"AUQC: {auqc_score:.3f}\")\n",
    "print (f\"Lift: {lift_score:.3f}\")\n",
    "print (f\"KRCC: {krcc_score:.3f}\")\n",
    "print (f\"seed: {seed}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
